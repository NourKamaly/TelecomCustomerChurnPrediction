{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09cb98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd,numpy as np, joblib, optuna\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import BaggingClassifier,GradientBoostingClassifier, RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import SGDClassifier,RidgeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB,GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b1869e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../2. Preprocessing/Processed data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2440e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Churn']\n",
    "features = df.drop(columns= ['Churn'],axis=1)\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(features, labels, random_state = 42, stratify = labels, test_size = 0.1)\n",
    "train_support= Counter(y_train)\n",
    "validation_support = Counter(y_validation)\n",
    "\n",
    "sm = SMOTE(random_state=27)\n",
    "x_train, y_train = sm.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1062e6a3-c1d3-4cc6-bb85-eca7a4d00cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_table(model_name, y_train, y_train_predictions, truth, predictions, train_support, validation_support):\n",
    "    precision_per_label = precision_score(truth, predictions, average=None)\n",
    "    recall_per_label = recall_score(truth, predictions, average=None)\n",
    "    f1_per_label = f1_score(truth, predictions, average=None)\n",
    "\n",
    "    precision_per_label_train = precision_score(y_train, y_train_predictions, average=None)\n",
    "    recall_per_label_train = recall_score(y_train, y_train_predictions, average=None)\n",
    "\n",
    "    metrics = pd.DataFrame(columns=['Model', 'Training Precision', 'Training Recall', 'Train Support',\n",
    "                                    'Validation Precision', 'Validation Recall', 'Validation F1 Score'],\n",
    "                           index=range(len(precision_per_label)))\n",
    "\n",
    "    for index in range(len(precision_per_label)):\n",
    "        metrics.at[index, 'Training Precision'] = precision_per_label_train[index]\n",
    "        metrics.at[index, 'Training Recall'] = recall_per_label_train[index]\n",
    "        metrics.at[index, 'Train Support'] = train_support[index]\n",
    "        metrics.at[index, 'Validation Support'] = validation_support[index]\n",
    "        metrics.at[index, 'Validation Precision'] = precision_per_label[index]\n",
    "        metrics.at[index, 'Validation Recall'] = recall_per_label[index]\n",
    "        metrics.at[index, 'Validation F1 Score'] = f1_per_label[index]\n",
    "\n",
    "    metrics['Model'] = model_name\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce99af22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: LogisticRegression\n",
      "Using model: AdaBoost\n",
      "Using model: GradientBoosting\n",
      "Using model: BaggingClassifier\n",
      "Using model: RandomForest\n",
      "Using model: eXtremeGradientBoosting\n",
      "Using model: KNN\n",
      "Using model: DecisionTree\n",
      "Using model: ExtraTreeClassifier\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    \"AdaBoost\" : AdaBoostClassifier(DecisionTreeClassifier(),n_estimators=10),\n",
    "    \"GradientBoosting\"      : GradientBoostingClassifier(),\n",
    "    \"BaggingClassifier\"  : BaggingClassifier(tree.DecisionTreeClassifier(random_state=1)),\n",
    "    \"RandomForest\"      : RandomForestClassifier(n_estimators=3),\n",
    "    \"eXtremeGradientBoosting\"     : XGBClassifier(objective= 'binary:logistic'),\n",
    "    \"KNN\"                : KNeighborsClassifier(n_neighbors = 30, weights = 'distance'),\n",
    "    \"DecisionTree\"      : DecisionTreeClassifier(),\n",
    "    \"ExtraTreeClassifier\"       : ExtraTreesClassifier(n_estimators=3)\n",
    "}\n",
    "metrics = pd.DataFrame()\n",
    "for name, model in models.items():\n",
    "    \n",
    "\n",
    "    print(f'Using model: {name}')\n",
    "    model.fit(x_train, y_train)\n",
    "    #joblib.dump(model,f'Saved Models/{name}.h5')\n",
    "    y_train_predictions = model.predict(x_train)\n",
    "    predictions = model.predict(x_validation)\n",
    "    metrics = pd.concat([metrics,create_metrics_table(name,y_train,y_train_predictions,y_validation, predictions, train_support,validation_support)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf234037-17fe-40b9-932b-3917aae6ab50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Precision</th>\n",
       "      <th>Training Recall</th>\n",
       "      <th>Train Support</th>\n",
       "      <th>Validation Precision</th>\n",
       "      <th>Validation Recall</th>\n",
       "      <th>Validation F1 Score</th>\n",
       "      <th>Validation Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>26161</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2907.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10592</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>26161</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2907.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10592</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.98</td>\n",
       "      <td>26161</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2907.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10592</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>26161</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2907.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>10592</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>26161</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2907.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>10592</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eXtremeGradientBoosting</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.98</td>\n",
       "      <td>26161</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.82</td>\n",
       "      <td>2907.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eXtremeGradientBoosting</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.77</td>\n",
       "      <td>10592</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>26161</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2907.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10592</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>26161</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>2907.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10592</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>26161</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2907.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10592</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1177.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Training Precision Training Recall Train Support  \\\n",
       "0       LogisticRegression               0.58            0.57         26161   \n",
       "1       LogisticRegression               0.58            0.58         10592   \n",
       "0                 AdaBoost               1.00            1.00         26161   \n",
       "1                 AdaBoost               1.00            1.00         10592   \n",
       "0         GradientBoosting               0.72            0.98         26161   \n",
       "1         GradientBoosting               0.97            0.63         10592   \n",
       "0        BaggingClassifier               0.98            1.00         26161   \n",
       "1        BaggingClassifier               1.00            0.98         10592   \n",
       "0             RandomForest               0.95            0.96         26161   \n",
       "1             RandomForest               0.96            0.94         10592   \n",
       "0  eXtremeGradientBoosting               0.81            0.98         26161   \n",
       "1  eXtremeGradientBoosting               0.97            0.77         10592   \n",
       "0                      KNN               1.00            1.00         26161   \n",
       "1                      KNN               1.00            1.00         10592   \n",
       "0             DecisionTree               1.00            1.00         26161   \n",
       "1             DecisionTree               1.00            1.00         10592   \n",
       "0      ExtraTreeClassifier               1.00            1.00         26161   \n",
       "1      ExtraTreeClassifier               1.00            1.00         10592   \n",
       "\n",
       "  Validation Precision Validation Recall Validation F1 Score  \\\n",
       "0                 0.76              0.57                0.65   \n",
       "1                 0.34              0.56                0.43   \n",
       "0                 0.73              0.72                0.73   \n",
       "1                 0.34              0.36                0.35   \n",
       "0                 0.72              0.97                0.83   \n",
       "1                 0.50              0.07                0.12   \n",
       "0                 0.73              0.90                0.81   \n",
       "1                 0.43              0.18                0.26   \n",
       "0                 0.74              0.77                0.75   \n",
       "1                 0.36              0.32                0.34   \n",
       "0                 0.74              0.92                0.82   \n",
       "1                 0.49              0.20                0.28   \n",
       "0                 0.76              0.52                0.62   \n",
       "1                 0.34              0.61                0.43   \n",
       "0                 0.73              0.71                0.72   \n",
       "1                 0.33              0.35                0.34   \n",
       "0                 0.73              0.78                0.75   \n",
       "1                 0.33              0.28                0.30   \n",
       "\n",
       "   Validation Support  \n",
       "0             2907.00  \n",
       "1             1177.00  \n",
       "0             2907.00  \n",
       "1             1177.00  \n",
       "0             2907.00  \n",
       "1             1177.00  \n",
       "0             2907.00  \n",
       "1             1177.00  \n",
       "0             2907.00  \n",
       "1             1177.00  \n",
       "0             2907.00  \n",
       "1             1177.00  \n",
       "0             2907.00  \n",
       "1             1177.00  \n",
       "0             2907.00  \n",
       "1             1177.00  \n",
       "0             2907.00  \n",
       "1             1177.00  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1d81f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 23:13:20,794] A new study created in memory with name: no-name-a251fd25-8c58-4cf2-aa95-40af99a52580\n",
      "[I 2025-06-04 23:13:21,830] Trial 0 finished with value: 0.26590909090909093 and parameters: {'max_depth': 11, 'min_samples_leaf': 6, 'min_samples_split': 2}. Best is trial 0 with value: 0.26590909090909093.\n",
      "[I 2025-06-04 23:13:22,991] Trial 1 finished with value: 0.34802158273381295 and parameters: {'max_depth': 20, 'min_samples_leaf': 19, 'min_samples_split': 15}. Best is trial 1 with value: 0.34802158273381295.\n",
      "[I 2025-06-04 23:13:24,128] Trial 2 finished with value: 0.34679981842941443 and parameters: {'max_depth': 28, 'min_samples_leaf': 22, 'min_samples_split': 22}. Best is trial 1 with value: 0.34802158273381295.\n",
      "[I 2025-06-04 23:13:24,446] Trial 3 finished with value: 0.43094672548354257 and parameters: {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 11}. Best is trial 3 with value: 0.43094672548354257.\n",
      "[I 2025-06-04 23:13:25,673] Trial 4 finished with value: 0.3223684210526316 and parameters: {'max_depth': 17, 'min_samples_leaf': 3, 'min_samples_split': 22}. Best is trial 3 with value: 0.43094672548354257.\n",
      "[I 2025-06-04 23:13:25,890] Trial 5 finished with value: 0.0 and parameters: {'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 3}. Best is trial 3 with value: 0.43094672548354257.\n",
      "[I 2025-06-04 23:13:26,977] Trial 6 finished with value: 0.32489645651173493 and parameters: {'max_depth': 22, 'min_samples_leaf': 25, 'min_samples_split': 30}. Best is trial 3 with value: 0.43094672548354257.\n",
      "[I 2025-06-04 23:13:27,752] Trial 7 finished with value: 0.2520045819014891 and parameters: {'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 6}. Best is trial 3 with value: 0.43094672548354257.\n",
      "[I 2025-06-04 23:13:29,108] Trial 8 finished with value: 0.34506437768240344 and parameters: {'max_depth': 32, 'min_samples_leaf': 9, 'min_samples_split': 9}. Best is trial 3 with value: 0.43094672548354257.\n",
      "[I 2025-06-04 23:13:30,139] Trial 9 finished with value: 0.31388329979879276 and parameters: {'max_depth': 13, 'min_samples_leaf': 24, 'min_samples_split': 12}. Best is trial 3 with value: 0.43094672548354257.\n",
      "[I 2025-06-04 23:13:30,456] Trial 10 finished with value: 0.0 and parameters: {'max_depth': 2, 'min_samples_leaf': 13, 'min_samples_split': 19}. Best is trial 3 with value: 0.43094672548354257.\n",
      "[I 2025-06-04 23:13:31,556] Trial 11 finished with value: 0.318550309966619 and parameters: {'max_depth': 22, 'min_samples_leaf': 32, 'min_samples_split': 13}. Best is trial 3 with value: 0.43094672548354257.\n",
      "[I 2025-06-04 23:13:32,772] Trial 12 finished with value: 0.3370685791125056 and parameters: {'max_depth': 22, 'min_samples_leaf': 16, 'min_samples_split': 16}. Best is trial 3 with value: 0.43094672548354257.\n",
      "[I 2025-06-04 23:13:33,871] Trial 13 finished with value: 0.32045240339302544 and parameters: {'max_depth': 17, 'min_samples_leaf': 19, 'min_samples_split': 10}. Best is trial 3 with value: 0.43094672548354257.\n",
      "[I 2025-06-04 23:13:34,509] Trial 14 finished with value: 0.2367066895368782 and parameters: {'max_depth': 7, 'min_samples_leaf': 12, 'min_samples_split': 17}. Best is trial 3 with value: 0.43094672548354257.\n",
      "[I 2025-06-04 23:13:35,604] Trial 15 finished with value: 0.3226107226107226 and parameters: {'max_depth': 25, 'min_samples_leaf': 28, 'min_samples_split': 29}. Best is trial 3 with value: 0.43094672548354257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 11}\n",
      "Best validation accuracy: 0.43094672548354257\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters controlling complexity\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 32)\n",
    "\n",
    "    # Create and train model\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Predict on validation set\n",
    "    preds = model.predict(x_validation)\n",
    "\n",
    "    # Use accuracy or another metric on validation set\n",
    "    f1 = f1_score(y_validation, preds)\n",
    "\n",
    "    # Optuna tries to maximize accuracy\n",
    "    return f1\n",
    "\n",
    "# Create study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=16)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation accuracy:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0, ignore_warnings=True)\n",
    "\n",
    "# Fit and evaluate models\n",
    "models, predictions = clf.fit(x_train, x_validation, y_train, y_validation)\n",
    "\n",
    "models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
